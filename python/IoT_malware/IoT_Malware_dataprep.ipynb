{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Machine Learning model for detecting Internet of Things Malware\n",
    "Based off AGUNG PAMBUDI's dataset published on Kaggle: https://www.kaggle.com/datasets/agungpambudi/network-malware-detection-connection-analysis/data\n",
    "\n",
    "The 12 source CSV files are about 3.2 GB total when uncompressed, and have a total of 25,011,015 lines in them.\n",
    "\n",
    "## Primary objectives:\n",
    "* develop a well generalized model with a targeted (TBD Metric) of (TBD metric value)\n",
    "* learn how to load/process data at gigabyte scale with on-prem hardware\n",
    "* show my InfoSec expertise by enhancing the existing dataset with valuable new features, and by providing quality data preparation/filtering\n",
    "\n",
    "## To Do Lists:\n",
    "### To Do - Optimization / Performance\n",
    "* switch input file from CSV to Parquet, partition data on disk\n",
    "* switch output from from CSV to Parquet\n",
    "* minimize memory utilization - select smallest appropriate datatypes for each feature\n",
    "* add support for multi-threading and vectorization, especially my custom feature functions\n",
    "* display progress meter for reading/writing files if possible, maybe ETA too\n",
    "\n",
    "### To Do - Data processing\n",
    "* check for bias in data, rebalance as needed\n",
    "* winsorize selected numerical features\n",
    "* normalize selected numerical features\n",
    "* investigate feature correlation with other features and the label, remove features that aren't providing value or that are too correlated with other features\n",
    "* display counts of missing values as a percentage of the whole\n",
    "* double check tunnel_parents column for unique values \n",
    "* Figure out what to do with missing values - remove or replace\n",
    "* OHE - get count of # of new columns created during process, display it\n",
    "* OHE - make sure it is not one-hot encoding Booleans\n",
    "\n",
    "### To Do - Feature enhancement ideas\n",
    "* check for service does NOT match the port/protocol because that is something suspicious and implies they're trying to hide something. Initial version: use hardcoded dict to support the 5-6 services listed. Enhanced: use third party service to do the lookup and support multiple port numbers for a single service (like http)\n",
    "* add support for threat intelligence feeds wrt IPs and other stuff\n",
    "\n",
    "### To Do - Research:\n",
    "* investigate other common Intrusion Detection System Indictors of Comprimise for possible feature development\n",
    "* investigate that latest MITRE ATT&CK framework methodologies and attacker trends for possible feature development\n",
    "\n",
    "### To Do - Modeling:\n",
    "* Build a Jupyter Notebook for training & optimizing Logistic Regression models on this data\n",
    "* Optimize the above model using gradient descent on hyperparameters\n",
    "* try out other model algorithms like decision tree, and others\n",
    "\n",
    "### To Do -  Longer term:\n",
    "* apply the model to my existing data lake of netflow, DNS, endpoint collection, and other data from SIEM.\n",
    "* implement model training as a pipeline to automatically create and optimize new models, roll them out\n",
    "* deploy the model to my local network and scan network traffic in near real time\n",
    "* investigate running in parallel computing, cloud providers, and/or GPU\n",
    "\n",
    "Misc notes:\n",
    "* Currently uses 8-9 GB of working set RAM, peaks around 12 GB during loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cython in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (3.0.10)\n",
      "Requirement already satisfied: numba in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (0.59.1)\n",
      "Requirement already satisfied: pandas in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: geoip2 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (4.8.0)\n",
      "Requirement already satisfied: humanize in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (4.9.0)\n",
      "Requirement already satisfied: pyarrow in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (16.1.0)\n",
      "Requirement already satisfied: matplotlib in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (3.9.0)\n",
      "Requirement already satisfied: seaborn in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (1.13.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from numba) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.6.2 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from geoip2) (3.9.5)\n",
      "Requirement already satisfied: maxminddb<3.0.0,>=2.5.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from geoip2) (2.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from geoip2) (2.32.2)\n",
      "Requirement already satisfied: setuptools>=60.0.0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from geoip2) (65.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/the-molecular-man/source_code/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# Performance improvements\n",
    "%pip install --upgrade pip\n",
    "%pip install cython numba pandas numpy geoip2 humanize pyarrow matplotlib seaborn scipy\n",
    "\n",
    "%load_ext Cython\n",
    "\n",
    "import numba\n",
    "numba.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipaddress\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# import re\n",
    "# from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geoip2.database\n",
    "import humanize\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_theme()\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_prefix = './data/CTU-IoT-Malware-Capture'\n",
    "csv_files_to_load = glob.glob('./data/CTU-IoT-Malware-Capture*.labeled.csv')\n",
    "training_outfile = output_file_prefix + \"_train.csv.gz\"\n",
    "\n",
    "ORIGINAL_LABEL_COLUMN_NAME = 'label'\n",
    "LABEL_COLUMN_NAME = 'label_bool'\n",
    "\n",
    "NORMALIZE_METHOD = \"min_max\"\n",
    "\n",
    "COLUMN_NAMES_CATEGORICAL = [ #'ip_asn', 'ip_dest_country',\n",
    "                            'id.resp_p', 'id.orig_p',\n",
    "                            'id.orig_h', 'id.resp_h',\n",
    "                            'proto', 'service', 'conn_state']\n",
    "\n",
    "# https://stackoverflow.com/questions/29245848/what-are-all-the-dtypes-that-pandas-recognizes\n",
    "FEATURE_PROPER_DATATYPES = {\n",
    "    'local_orig':   'Int64',\n",
    "    'local_resp':   'Int64',\n",
    "    'missed_bytes': 'Int64',\n",
    "    'id.resp_p':    'category',\n",
    "    'id.orig_p':    'category',\n",
    "    'id.orig_h':    'category',\n",
    "    'id.resp_h':    'category',\n",
    "    'proto':        'category',\n",
    "    'service':      'category',\n",
    "    'conn_state':   'category',\n",
    "    'tunnel_parents':   'category',\n",
    "    'duration':     'float32',   # np.float32\n",
    "    'history':      'category'\n",
    "    # 'ts': have to pass parameters\n",
    "    \n",
    "    #'orig_bytes':   int,       # has NaN values, so have to use float\n",
    "    #'resp_bytes':   int        # has NaN values\n",
    "    }\n",
    "\n",
    "columns_to_OHE = ['proto', 'service', 'conn_state', \n",
    "                  'history', 'ip_dest_country'] \n",
    "                    #'id.resp_h', 'id.orig_h']\n",
    "                    \n",
    "SERVICE_TO_PROTOCOL_AND_PORT_MAPPINGS = {\n",
    "  'ssh': {'protocol': 'tcp', 'port': 22},\n",
    "  'dns': {'protocol': 'udp', 'port': 53},\n",
    "}\n",
    "\n",
    "geoip_country = geoip2.database.Reader('./geoip/GeoLite2-Country_20240308/GeoLite2-Country.mmdb')\n",
    "geoip_asn     = geoip2.database.Reader('./geoip/GeoLite2-ASN_20240308/GeoLite2-ASN.mmdb')\n",
    "\n",
    "def get_human_friendly_mem_size(dfx):\n",
    "    return humanize.naturalsize(dfx.memory_usage(index=True, deep=True))\n",
    "    #  sys.getsizeof(objname))\n",
    "\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into a Pandas dataframe\n",
    "Define the path to the dataset file\n",
    "Define the name of the label column\n",
    "\n",
    "performance\n",
    "|Runtime|Parser Engine|specified datatypes|specified index|specified chunksize|memory_map|df.memory_usage|\n",
    "|---|---|---|---|---|---|---|\n",
    "|96 sec|unspecifed|unspecifed|unspecified|unspecified|unspecified (Default: False)|?|\n",
    "|3.5 min|unspecifed|almost all|uid|unspecified|unspecified (Default: False)|?|\n",
    "|4 min 6 sec|unspecifed|almost all|uid|unspecified|True|16.9 GB|\n",
    "|2 min 7 sec|pyarrow|almost all|uid|unspecified|True|14.3 GB|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/CTU-IoT-Malware-Capture-3-1conn.log.labeled.csv\n",
      "./data/CTU-IoT-Malware-Capture-21-1conn.log.labeled.csv\n",
      "./data/CTU-IoT-Malware-Capture-34-1conn.log.labeled.csv\n",
      "./data/CTU-IoT-Malware-Capture-44-1conn.log.labeled.csv\n",
      "./data/CTU-IoT-Malware-Capture-20-1conn.log.labeled.csv\n",
      "./data/CTU-IoT-Malware-Capture-8-1conn.log.labeled.csv\n",
      "./data/CTU-IoT-Malware-Capture-42-1conn.log.labeled.csv\n"
     ]
    }
   ],
   "source": [
    "# load a directory of CSV files:\n",
    "# chunksizeint\n",
    "dfs = []\n",
    "for iter_csv_file in csv_files_to_load:\n",
    "    # filesize_MB = int(os.stat(iter_csv_file).st_size / (1024 * 1024))\n",
    "    # if filesize_MB >= 5:\n",
    "    #     print(f'skipping file {filesize_MB}, too big at {filesize_MB} MB')\n",
    "    #     continue\n",
    "    # /var/folders/90/cd8pt9qd43q0svfjsljg9ccr0000gn/T/ipykernel_60137/4122006169.py:16: DtypeWarning: Columns (7,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-chunking\n",
    "    # https://stackoverflow.com/questions/66346343/can-i-load-multiple-csv-files-using-pyarrow\n",
    "    # https://arrow.apache.org/docs/2.0/python/generated/pyarrow.csv.ReadOptions.html#pyarrow.csv.ReadOptions\n",
    "    print(iter_csv_file)\n",
    "    df_temp = pd.read_csv(iter_csv_file,\n",
    "                          index_col='uid',\n",
    "                          #engine='pyarrow',        # causes issues wiith delimiters sometimes\n",
    "                          dtype=FEATURE_PROPER_DATATYPES,\n",
    "                          delimiter='|',\n",
    "                          na_values='-'\n",
    "    )\n",
    "    dfs.append(df_temp)\n",
    "    del df_temp\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                  132\n",
       "ts                 1606472\n",
       "id.orig_h         13780568\n",
       "id.orig_p         12476827\n",
       "id.resp_h         14163874\n",
       "id.resp_p         11993825\n",
       "proto             12049748\n",
       "service            6761894\n",
       "duration            803236\n",
       "orig_bytes         1606472\n",
       "resp_bytes         1606472\n",
       "conn_state        11866311\n",
       "local_orig         1807281\n",
       "local_resp         1807281\n",
       "missed_bytes       1807281\n",
       "history           11687799\n",
       "orig_pkts          1606472\n",
       "orig_ip_bytes      1606472\n",
       "resp_pkts          1606472\n",
       "resp_ip_bytes      1606472\n",
       "tunnel_parents      200809\n",
       "label             13338996\n",
       "detailed-label    14122418\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html\n",
    "# get_human_friendly_mem_size(df)\n",
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customized variables for this dataset\n",
    "\n",
    "Feature description from documentation: https://www.kaggle.com/datasets/agungpambudi/network-malware-detection-connection-analysis/data\n",
    "\n",
    "|Field Name|Description|Type|\n",
    "| ----------- | ----------- | ----------- |\n",
    "|ts|The timestamp of the connection event.|time|\n",
    "|uid|A unique identifier for the connection.|string|\n",
    "|id.orig_h|The source IP address.|addr|\n",
    "|id.orig_p|The source port.|port|\n",
    "|id.resp_h|The destination IP address.|addr|\n",
    "|id.resp_p|The destination port.|port|\n",
    "|proto|The network protocol used (e.g., 'tcp').|enum|\n",
    "|service|The service associated with the connection.|string|\n",
    "|duration|The duration of the connection.|interval|\n",
    "|orig_bytes|The number of bytes sent from the source to the destination.|count|\n",
    "|resp_bytes|The number of bytes sent from the destination to the source.|count|\n",
    "|conn_state|The state of the connection.|string|\n",
    "|local_orig|Indicates whether the connection is considered local or not.|bool|\n",
    "|local_resp|Indicates whether the connection is considered local or not.|bool|\n",
    "|missed_bytes|The number of missed bytes in the connection.|count|\n",
    "|history|A history of connection states.|string|\n",
    "|orig_pkts|The number of packets sent from the source to the destination.|count|\n",
    "|orig_ip_bytes|The number of IP bytes sent from the source to the destination.|count|\n",
    "|resp_pkts|The number of packets sent from the destination to the source.|count|\n",
    "|resp_ip_bytes|The number of IP bytes sent from the destination to the source.|count|\n",
    "|tunnel_parents|Indicates if this connection is part of a tunnel.|set[string]|\n",
    "|label|A label associated with the connection (e.g., 'Malicious' or 'Benign').|string|\n",
    "|detailed-label|A more detailed description or label for the connection.|string|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'irc', 'ssh', 'dns', 'dhcp', 'http', 'ssl'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['service'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "More transform ideas:\n",
    "* service vs port/protcol mismatch\n",
    "* first time contact between client/server\n",
    "* receiving end high port\n",
    "* total last 24 hour bandwidth between client/server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts                       float64\n",
       "id.orig_h               category\n",
       "id.orig_p               category\n",
       "id.resp_h               category\n",
       "id.resp_p               category\n",
       "proto                   category\n",
       "service                 category\n",
       "duration                 float32\n",
       "orig_bytes               float64\n",
       "resp_bytes               float64\n",
       "conn_state              category\n",
       "local_orig                 Int64\n",
       "local_resp                 Int64\n",
       "missed_bytes               Int64\n",
       "history                 category\n",
       "orig_pkts                float64\n",
       "orig_ip_bytes            float64\n",
       "resp_pkts                float64\n",
       "resp_ip_bytes            float64\n",
       "tunnel_parents          category\n",
       "label                     object\n",
       "detailed-label            object\n",
       "label_bool                  bool\n",
       "is_tunneled                 bool\n",
       "ts_converted      datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the label as boolean\n",
    "df[LABEL_COLUMN_NAME] = df[ORIGINAL_LABEL_COLUMN_NAME].isin(['Malicious   C&C']).astype(int).astype(bool)\n",
    "\n",
    "for colname, newdatatype in FEATURE_PROPER_DATATYPES.items():\n",
    "    df[colname] = df[colname].astype(newdatatype)\n",
    "\n",
    "# for iter_colname in COLUMN_NAMES_CATEGORICAL:\n",
    "#     df[iter_colname] = df[iter_colname].astype('category')\n",
    "\n",
    "df['is_tunneled'] = not(df['tunnel_parents'].isna)\n",
    "\n",
    "# converting the date to timestamp,\n",
    "# need the unit='s' to convert Unix time\n",
    "df['ts_converted'] = pd.to_datetime(\n",
    "    df['ts'], errors=\"raise\",\n",
    "    unit='s'\n",
    ")\n",
    "\n",
    "# df.set_index('uid', inplace=True)     # causes issues sometimes\n",
    "# IP_ADDRESS_COLUMN_NAMES = ['id.orig_h', 'id.resp_h']\n",
    "# for iter_colname in IP_ADDRESS_COLUMN_NAMES:\n",
    "#     df[iter_colname] = df[iter_colname].apply(ipaddress.ip_address)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>id.orig_h</th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "      <th>label</th>\n",
       "      <th>detailed-label</th>\n",
       "      <th>label_bool</th>\n",
       "      <th>is_tunneled</th>\n",
       "      <th>ts_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38792</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.998333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:41.866499901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38792</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:48.874876022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38793</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.997182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:52.877722025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts    id.orig_h id.orig_p       id.resp_h id.resp_p proto  \\\n",
       "0  1.526756e+09  192.168.2.5     38792  200.168.87.203     59353   tcp   \n",
       "1  1.526756e+09  192.168.2.5     38792  200.168.87.203     59353   tcp   \n",
       "2  1.526756e+09  192.168.2.5     38793  200.168.87.203     59353   tcp   \n",
       "\n",
       "  service  duration  orig_bytes  resp_bytes  ... orig_pkts  orig_ip_bytes  \\\n",
       "0     NaN  2.998333         0.0         0.0  ...       3.0          180.0   \n",
       "1     NaN       NaN         NaN         NaN  ...       1.0           60.0   \n",
       "2     NaN  2.997182         0.0         0.0  ...       3.0          180.0   \n",
       "\n",
       "   resp_pkts  resp_ip_bytes tunnel_parents      label  \\\n",
       "0        0.0            0.0            NaN  Malicious   \n",
       "1        0.0            0.0            NaN  Malicious   \n",
       "2        0.0            0.0            NaN  Malicious   \n",
       "\n",
       "              detailed-label  label_bool  is_tunneled  \\\n",
       "0  PartOfAHorizontalPortScan       False        False   \n",
       "1  PartOfAHorizontalPortScan       False        False   \n",
       "2  PartOfAHorizontalPortScan       False        False   \n",
       "\n",
       "                   ts_converted  \n",
       "0 2018-05-19 18:57:41.866499901  \n",
       "1 2018-05-19 18:57:48.874876022  \n",
       "2 2018-05-19 18:57:52.877722025  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some sample data after the transforms\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "local_resp        200809\n",
       "tunnel_parents    200809\n",
       "local_orig        200809\n",
       "service           188811\n",
       "duration          101072\n",
       "orig_bytes        101072\n",
       "resp_bytes        101072\n",
       "detailed-label     40976\n",
       "history             1208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locating missing values:\n",
    "nan_count = np.sum(df.isnull(), axis=0).sort_values(ascending=False)\n",
    "\n",
    "# display just columns that have at least 1 missing value:\n",
    "nan_count[nan_count > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns that the model doesn't use\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id.orig_h              category\n",
       "id.orig_p              category\n",
       "id.resp_h              category\n",
       "id.resp_p              category\n",
       "proto                  category\n",
       "service                category\n",
       "duration                float32\n",
       "orig_bytes              float64\n",
       "resp_bytes              float64\n",
       "conn_state             category\n",
       "local_orig                Int64\n",
       "local_resp                Int64\n",
       "missed_bytes              Int64\n",
       "history                category\n",
       "orig_pkts               float64\n",
       "orig_ip_bytes           float64\n",
       "resp_pkts               float64\n",
       "resp_ip_bytes           float64\n",
       "label_bool                 bool\n",
       "is_tunneled                bool\n",
       "ts_converted     datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\n",
    "    columns=[\n",
    "        ORIGINAL_LABEL_COLUMN_NAME,     # was replaced\n",
    "        \"detailed-label\",               # will be used in future version of this Notebook\n",
    "        \"ts\",                           # was converted to a new column\n",
    "        # \"uid\",                           # unique identifier, not used by model\n",
    "        \"tunnel_parents\"                # documentation isn't clear enough on what this is or how it is formatted or why to be useful\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations - Data Enrichment via adding features\n",
    "\n",
    "This step takes the longest - about 8 minutes on a MacBook air w/o vectorizing via numba or specifying # of threads via "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n",
      "[None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id.orig_h                category\n",
       "id.orig_p                category\n",
       "id.resp_h                category\n",
       "id.resp_p                category\n",
       "proto                    category\n",
       "service                  category\n",
       "duration                  float32\n",
       "orig_bytes                float64\n",
       "resp_bytes                float64\n",
       "conn_state               category\n",
       "local_orig                  Int64\n",
       "local_resp                  Int64\n",
       "missed_bytes                Int64\n",
       "history                  category\n",
       "orig_pkts                 float64\n",
       "orig_ip_bytes             float64\n",
       "resp_pkts                 float64\n",
       "resp_ip_bytes             float64\n",
       "label_bool                   bool\n",
       "is_tunneled                  bool\n",
       "ts_converted       datetime64[ns]\n",
       "ip_dest_country            object\n",
       "ip_asn                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure and load the GeoIP databases\n",
    "# %pip install geoip2\n",
    "# restart the kernel\n",
    "\n",
    "# https://dev.maxmind.com/geoip/geolite2-free-geolocation-data?lang=en  \n",
    "# https://www.maxmind.com/en/accounts/985797/geoip/downloads\n",
    "# https://github.com/maxmind/GeoIP2-python?tab=readme-ov-file#database-usage\n",
    "\n",
    "# @numba.vectorize\n",
    "def ip_to_country(ip_as_str):\n",
    "    try:\n",
    "        ip = ipaddress.ip_address(ip_as_str)\n",
    "        if ip.is_global:\n",
    "            return geoip_country.country(ip).country.name\n",
    "    finally:\n",
    "        return None\n",
    "\n",
    "# @numba.vectorize\n",
    "def ip_to_asn(ip_as_str):\n",
    "    try:\n",
    "        ip = ipaddress.ip_address(ip_as_str)\n",
    "        if ip.is_global:\n",
    "            return geoip_asn.asn(ip).autonomous_system_number\n",
    "    finally:\n",
    "        return None\n",
    "\n",
    "# GeoIP\n",
    "df['ip_dest_country'] = df['id.resp_h'].apply(ip_to_country)\n",
    "df['ip_asn']          = df['id.resp_h'].apply(ip_to_asn)\n",
    "\n",
    "print(df['ip_dest_country'].unique().tolist())\n",
    "print(df['ip_asn'].unique().tolist())\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting strings to one-hot encoded columns\n",
    "Locate string columns that have a small number of unique values and replace them with one-hot encoded versions, then remove the original column.\n",
    "\n",
    "Runtime: 3 min on Macbook air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded: proto into proto*\n",
      "One-hot encoded: service into service*\n",
      "One-hot encoded: conn_state into conn_state*\n",
      "One-hot encoded: history into history*\n",
      "One-hot encoded: ip_dest_country into ip_dest_country*\n"
     ]
    }
   ],
   "source": [
    "for iter_column_name in columns_to_OHE:\n",
    "    # define a new column name\n",
    "    new_column_prefix = iter_column_name # + '_onehot_'\n",
    "    \n",
    "    # create a one-hot encoded version in a new dataframe\n",
    "    temp_df = pd.get_dummies(df[iter_column_name], prefix=new_column_prefix)\n",
    "\n",
    "    # merge the new dataframe into the existing one\n",
    "    df = df.join(temp_df)\n",
    "\n",
    "    # remove the original column now that it has been encoded \n",
    "    # into the existing dataframe\n",
    "    df.drop(columns=iter_column_name, inplace=True)\n",
    "    \n",
    "    print(f'One-hot encoded: {iter_column_name} into {new_column_prefix}*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip_asn    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Everything should be reduced to numbers at this point\n",
    "\n",
    "list_of_string_columns = df.select_dtypes(include=object).columns.tolist()\n",
    "\n",
    "# create a Pandas Series that lists the string columns by ascending counts\n",
    "df_unique_string_vals = df[list_of_string_columns].nunique().sort_values(ascending=True)\n",
    "df_unique_string_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-order the columns\n",
    "Sort the column names alphabetically, but make sure the 'label' column is always last.\n",
    "AWS Sagemaker cares about the order and having the label be last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabetically sort the column names, but leave the label as the last column\n",
    "column_order = sorted(df.columns)\n",
    "column_order.remove(LABEL_COLUMN_NAME)\n",
    "column_order.append(LABEL_COLUMN_NAME)\n",
    "df = df.reindex(column_order, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conn_state_OTH                bool\n",
       "conn_state_REJ                bool\n",
       "conn_state_RSTO               bool\n",
       "conn_state_RSTR               bool\n",
       "conn_state_RSTRH              bool\n",
       "                         ...      \n",
       "service_irc                   bool\n",
       "service_ssh                   bool\n",
       "service_ssl                   bool\n",
       "ts_converted        datetime64[ns]\n",
       "label_bool                    bool\n",
       "Length: 147, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the final datatypes before exporting to CSV\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conn_state_OTH</th>\n",
       "      <th>conn_state_REJ</th>\n",
       "      <th>conn_state_RSTO</th>\n",
       "      <th>conn_state_RSTR</th>\n",
       "      <th>conn_state_RSTRH</th>\n",
       "      <th>conn_state_S0</th>\n",
       "      <th>conn_state_S1</th>\n",
       "      <th>conn_state_S2</th>\n",
       "      <th>conn_state_S3</th>\n",
       "      <th>conn_state_SF</th>\n",
       "      <th>...</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>service_dhcp</th>\n",
       "      <th>service_dns</th>\n",
       "      <th>service_http</th>\n",
       "      <th>service_irc</th>\n",
       "      <th>service_ssh</th>\n",
       "      <th>service_ssl</th>\n",
       "      <th>ts_converted</th>\n",
       "      <th>label_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:41.866499901</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:48.874876022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:52.877722025</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:57:59.884958982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-19 18:58:03.888751030</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   conn_state_OTH  conn_state_REJ  conn_state_RSTO  conn_state_RSTR  \\\n",
       "0           False           False            False            False   \n",
       "1           False           False            False            False   \n",
       "2           False           False            False            False   \n",
       "3           False           False            False            False   \n",
       "4           False           False            False            False   \n",
       "\n",
       "   conn_state_RSTRH  conn_state_S0  conn_state_S1  conn_state_S2  \\\n",
       "0             False           True          False          False   \n",
       "1             False           True          False          False   \n",
       "2             False           True          False          False   \n",
       "3             False           True          False          False   \n",
       "4             False           True          False          False   \n",
       "\n",
       "   conn_state_S3  conn_state_SF  ...  resp_ip_bytes  resp_pkts  service_dhcp  \\\n",
       "0          False          False  ...            0.0        0.0         False   \n",
       "1          False          False  ...            0.0        0.0         False   \n",
       "2          False          False  ...            0.0        0.0         False   \n",
       "3          False          False  ...            0.0        0.0         False   \n",
       "4          False          False  ...            0.0        0.0         False   \n",
       "\n",
       "   service_dns  service_http  service_irc  service_ssh  service_ssl  \\\n",
       "0        False         False        False        False        False   \n",
       "1        False         False        False        False        False   \n",
       "2        False         False        False        False        False   \n",
       "3        False         False        False        False        False   \n",
       "4        False         False        False        False        False   \n",
       "\n",
       "                   ts_converted  label_bool  \n",
       "0 2018-05-19 18:57:41.866499901       False  \n",
       "1 2018-05-19 18:57:48.874876022       False  \n",
       "2 2018-05-19 18:57:52.877722025       False  \n",
       "3 2018-05-19 18:57:59.884958982       False  \n",
       "4 2018-05-19 18:58:03.888751030       False  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the readers\n",
    "geoip_country.close()\n",
    "geoip_asn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200809\n"
     ]
    }
   ],
   "source": [
    "# size output\n",
    "\n",
    "# print(df.size) # total number of cells (rows times columns)\n",
    "print(df.shape[0])\n",
    "\n",
    "# print(humanize.naturalsize(sys.getsizeof(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing training and prediction data into CSV files\n",
    "\n",
    "full dataframe has 25011003 rows\n",
    "\n",
    "|file type|# of rows|size|runtime|filename|expanded file size (MB)|compression ratio (%)|% of data exported|Est runtime for full data|Est full file size|\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "|CSV|509191|898 MB|?|CTU-IoT-Malware-Capture_train.csv|same|N/A|2.0%|?|43 GB|\n",
    "|XZ|379831|12 MB|10 min 36 sec|CTU-IoT-Malware-Capture_train.xz|703 MB|98%|1.5186%|11.5 hours|790 MB|\n",
    "|CSV|40261|74.5 MB|60 sec|CTU-IoT-Malware-Capture_train.csv|same|N/A|0.001609731524961|10 hours |45 GB|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to new file:\n",
      "./data/CTU-IoT-Malware-Capture_train.csv.gz\n",
      "output file size: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Runtime on Macbook air with full dataset to uncompressed file: at least 8 min\n",
    "#   CSV is mariginally faster than XZ, but takes up way more space\n",
    "#   https://dask.pydata.org/en/latest/diagnostics-local.html\n",
    "#   increase # of rows/block size\n",
    "#   https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "\n",
    "# Create a training/test dataset and output to CSV\n",
    "df.to_csv(training_outfile,\n",
    "        sep='|',\n",
    "        header=True,\n",
    "        #index=False,\n",
    "        chunksize=1000000,\n",
    "        compression='gzip',\n",
    "        encoding='utf-8')\n",
    "\n",
    "print(f\"Training data saved to new file:\\n{training_outfile}\")\n",
    "\n",
    "output_filesize = humanize.naturalsize(os.stat(training_outfile).st_size)\n",
    "print(f'output file size: {output_filesize}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
