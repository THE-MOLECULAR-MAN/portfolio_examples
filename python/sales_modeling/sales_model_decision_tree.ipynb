{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Opps - Decision Tree Model\n",
    "\n",
    "This notebook builds a Decision Tree model from training data in CSV format. It relies on a CSV file output from the Sales data preparation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some exclusions for PEP8 that don't apply when the Jupyter Notebook\n",
    "#   is exported to .py file\n",
    "# pylint: disable=pointless-statement\n",
    "# pylint: disable=fixme\n",
    "# pylint: disable=expression-not-assigned\n",
    "# pylint: disable=missing-module-docstring\n",
    "# pylint: disable=invalid-name\n",
    "\n",
    "# %pip install scikit-learn\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as sklm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting custom parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of training data to use for test\n",
    "TEST_SIZE = 0.33\n",
    "\n",
    "# random seed\n",
    "RANDOM_STATE = 1234\n",
    "\n",
    "# the name for the column that indicates the label/target\n",
    "# the training CSV file should have headers\n",
    "LABEL_COLUMN_NAME = \"Won\"\n",
    "\n",
    "# First search range for Max Tree Depth to find a local max:\n",
    "# max_depth_range = [2**i for i in range(6)] # ranges from 1 to 2^5\n",
    "\n",
    "# second search range, zooming in on near the broad maximum found\n",
    "MAX_TREE_DEPTH_RANGE = range(3, 20, 2)\n",
    "\n",
    "# original test to look for local maximum broadly\n",
    "# leaf_range = [2**i for i in range(8)]\n",
    "# new range to local specific max:\n",
    "MIN_SAMPLES_TO_MAKE_LEAF_RANGE = range(2, 20, 2)\n",
    "\n",
    "# acceptable values: accuracy, f1, precision, recall\n",
    "METRIC_TO_MEASURE = \"accuracy\"\n",
    "\n",
    "# \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "\n",
    "def get_best_hyperparameter_value(hyperparameter_list, metric_list):\n",
    "    index_max = max(range(len(metric_list)), key=metric_list.__getitem__)\n",
    "    return hyperparameter_list[index_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\n",
    "   os.getcwd(), \"data\", \"dummy_sfdc_data_train.csv\"\n",
    ")\n",
    "# filename = \"sales_data_train.csv\"\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that there are only numeric and boolean datatypes left\n",
    "# there should not be any strings left\n",
    "for index, value in df.dtypes.items():\n",
    "    assert value in [\n",
    "        \"float64\",\n",
    "        \"bool\",\n",
    "        \"int64\",\n",
    "    ], f\"Column name {index} is not numeric or boolean- found {value}. All features at this point should be numeric or boolean. Exiting.\"\n",
    "\n",
    "print(\"Feature datatype check passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that the data does not contain any missing values.\n",
    "The absense of missing values is necessary for training a Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a Panda Series of the columns and number of NaNs in each one\n",
    "nan_count = np.sum(df.isnull(), axis=0)\n",
    "\n",
    "# iterate through the Series. It could be easier to just throw and exception if\n",
    "# any have a value of zero.\n",
    "for index, value in nan_count.items():\n",
    "    assert (\n",
    "        value == 0\n",
    "    ), f\"Column name {df.columns[index]} (index = {index}) has {value} missing values (NaN). Decision trees cannot have any missing values. Exiting.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[LABEL_COLUMN_NAME]\n",
    "X = df.drop(columns=LABEL_COLUMN_NAME, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function that builds a model given hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_DT(X_train1, X_test1, y_train1, y_test1, leaf1, depth1, crit=\"entropy\"):\n",
    "    \"\"\"\n",
    "    Fit a Decision Tree classifier to the training data X_train, y_train.\n",
    "    Return the accuracy of resulting predictions on the test set.\n",
    "    Parameters:\n",
    "        leaf := The minimum number of samples required to be at a leaf node\n",
    "        depth := The maximum depth of the tree\n",
    "        crit := The function to be used to measure the quality of a split.\n",
    "\n",
    "                Default: gini.\n",
    "    \"\"\"\n",
    "    # Instantiate the  Scikit-learn DecisionTreeClassifier model object\n",
    "    # with specific hyperparameters\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=depth1, min_samples_leaf=leaf1, criterion=crit\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training data below\n",
    "    model.fit(X_train1, y_train1)\n",
    "\n",
    "    # Make predictions on the test data and store the results\n",
    "    class_label_predictions = model.predict(X_test1)\n",
    "\n",
    "    if sum(class_label_predictions) == 0:\n",
    "        prec = 0\n",
    "        print(f'WARNING: No True predictions for model with max_depth={depth1} min_samples_leaf={leaf1}. Force setting precision = {prec}')\n",
    "    else:\n",
    "        prec = sklm.precision_score(y_test1, class_label_predictions)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": sklm.accuracy_score(y_test1, class_label_predictions),\n",
    "        \"f1\": sklm.f1_score(y_test1, class_label_predictions),\n",
    "        \"precision\": prec,\n",
    "        \"recall\": sklm.recall_score(y_test1, class_label_predictions),\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on different hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter value: Maximum Depth of Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the min number of samples to create a leaf as 1 for this\n",
    "# first iteration\n",
    "min_samples_to_create_leaf = 5\n",
    "\n",
    "# initialize an empty list to store results\n",
    "metrics_list = []\n",
    "\n",
    "# iterate on the list of max depths\n",
    "for iter_max_depth_value in MAX_TREE_DEPTH_RANGE:\n",
    "    # train the model and store the metric\n",
    "    resulting_metrics = train_test_DT(\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        min_samples_to_create_leaf,\n",
    "        iter_max_depth_value,\n",
    "    )\n",
    "\n",
    "    # add the results to the list for future plotting\n",
    "    metrics_list.append(float(resulting_metrics[METRIC_TO_MEASURE]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "p = sns.lineplot(\n",
    "    x=MAX_TREE_DEPTH_RANGE, y=metrics_list, marker=\"o\", label=\"Full training set\"\n",
    ")\n",
    "\n",
    "plt.title(f\"Test set {METRIC_TO_MEASURE} of the Decision Tree predictions\")\n",
    "ax.set_xlabel(\"Max depth of Decision Tree\")\n",
    "ax.set_ylabel(METRIC_TO_MEASURE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the best value for hyperparameter: Maximum Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMUM_MAX_DEPTH = get_best_hyperparameter_value(MAX_TREE_DEPTH_RANGE, metrics_list)\n",
    "print(OPTIMUM_MAX_DEPTH)\n",
    "\n",
    "# best max depth value found:\n",
    "# OPTIMUM_MAX_DEPTH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty list to store results\n",
    "metrics_list_leaf = []\n",
    "\n",
    "# iterate through list of potential leaf values\n",
    "for leaf in MIN_SAMPLES_TO_MAKE_LEAF_RANGE:\n",
    "    resulting_metrics = train_test_DT(X_train, X_test, y_train, y_test, leaf, OPTIMUM_MAX_DEPTH)\n",
    "    metrics_list_leaf.append(float(resulting_metrics[METRIC_TO_MEASURE]))\n",
    "\n",
    "# print(metrics_list_leaf)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "p = sns.lineplot(\n",
    "    x=MIN_SAMPLES_TO_MAKE_LEAF_RANGE,\n",
    "    y=metrics_list_leaf,\n",
    "    marker=\"o\",\n",
    "    label=\"Full training set\",\n",
    ")\n",
    "\n",
    "plt.title(f\"Test set {METRIC_TO_MEASURE} of the DT predictions, Leaf\")\n",
    "ax.set_xlabel(\"minimum number of samples required to be at a leaf node\")\n",
    "ax.set_ylabel(METRIC_TO_MEASURE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the best value for hyperparameter: Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMUM_LEAF = get_best_hyperparameter_value(MIN_SAMPLES_TO_MAKE_LEAF_RANGE, metrics_list_leaf)\n",
    "print(OPTIMUM_LEAF)\n",
    "# OPTIMUM_LEAF = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the final model that uses both of the optimum values:\n",
    "final_metrics = train_test_DT(\n",
    "    X_train, X_test, y_train, y_test, OPTIMUM_LEAF, OPTIMUM_MAX_DEPTH\n",
    ")\n",
    "final_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing hyperparmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter_metric in [\"accuracy\", \"f1\", \"precision\", \"recall\"]:\n",
    "    best_leaf = 0\n",
    "    best_depth = 0\n",
    "    best_metric = 0\n",
    "\n",
    "    for r, iter_leaf in enumerate(MIN_SAMPLES_TO_MAKE_LEAF_RANGE):\n",
    "        \n",
    "        for c, iter_max_depth_value in enumerate(MAX_TREE_DEPTH_RANGE):\n",
    "            # train the model and store the accuracy\n",
    "            resulting_metrics = train_test_DT(\n",
    "                X_train, X_test, y_train, y_test, iter_leaf, iter_max_depth_value\n",
    "            )\n",
    "\n",
    "            met = resulting_metrics[iter_metric]\n",
    "\n",
    "            if met > best_metric:\n",
    "                best_leaf = iter_leaf\n",
    "                best_depth = iter_max_depth_value\n",
    "                best_metric = met\n",
    "\n",
    "    print(\n",
    "        f\"Best leaf value = {best_leaf:4}, Best max depth = {best_depth:4}, resulted in highest value of {iter_metric:10} = {best_metric:.5}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
