{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & Modeling - Experiment 5b - Using PCA for dimensional reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "from   sklearn.decomposition import PCA\n",
    "# from   sklearn.model_selection import GridSearchCV, train_test_split\n",
    "# import sklearn.metrics as skm\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "from   xgboost import XGBClassifier\n",
    "\n",
    "import saleslib                         # my custom module\n",
    "importlib.reload(saleslib)              # reload it since I'm frequently making changes.\n",
    "from saleslib import LABEL_COLUMN_NAME, RANDOM_STATE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "saleslib.initialize_random_seeds()\n",
    "saleslib.initialize_display_options()\n",
    "\n",
    "input_filepath = os.path.join('data', 'raw_CRM_opps_export-dummydata.csv')\n",
    "df_orig        = saleslib.load_data_raw(input_filepath)\n",
    "df_exp         = saleslib.full_pipeline(df_orig)        # does a variety of things but does not standardize the data\n",
    "\n",
    "df       = df_exp.copy()\n",
    "y        = df[LABEL_COLUMN_NAME]\n",
    "X        = df.drop(columns=LABEL_COLUMN_NAME, axis=1)\n",
    "\n",
    "# Standardize the data\n",
    "sc       = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "# variables not often changed in experiments\n",
    "testsize_list     = [0.2]              # not used at the moment\n",
    "random_state_list = [123456]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurables for this specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list      = ['Precision', 'Recall', 'roc_auc', 'F1', 'roc_auc_score', \n",
    "                     'neg_log_loss', 'Brier Score Loss', \n",
    "                     'auc'] \n",
    "\n",
    "# METRICS_OUTPUT_PATH = os.path.join('metrics_history', 'sales_modeling_metrics-endor.csv')                    \n",
    "METRICS_OUTPUT_PATH = os.path.join('metrics_history', 'sales_modeling_metrics-homelab.csv')\n",
    "\n",
    "param_grid = {\n",
    "   'max_depth':     [2, 4, 8, 16],\n",
    "   'n_estimators':  [100, 1000, 10000, 40000],\n",
    "   'learning_rate': [0.85, 0.05]\n",
    "}\n",
    "\n",
    "\n",
    "CV_list            = [7, 9, 11]\n",
    "PCA_NUM_COMPONENTS = [3, 4, 5, 6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# metrics_list      = ['Brier Score Loss']\n",
    "# METRICS_OUTPUT_PATH = os.path.join('metrics_history', 'sales_modeling_metrics-homelab.csv')\n",
    "# param_grid = {\n",
    "# \t'max_depth': [8, 16, 24], \n",
    "# \t'n_estimators': [5000, 10000, 20000], \n",
    "# \t'learning_rate': [0.01]}\n",
    "# CV_list            = [5, 7, 9, 11]\n",
    "# PCA_NUM_COMPONENTS = [2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the experiment loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Starting experiment at {saleslib.get_current_timestamp()}')\n",
    "\n",
    "for n in PCA_NUM_COMPONENTS:\n",
    "   saleslib.initialize_random_seeds()\n",
    "   print(f'Start Loop - Num PCA Components = {n}')\n",
    "\n",
    "   pca = PCA(n_components=n)\n",
    "   pca.fit(X_scaled)\n",
    "   X_pca = pca.transform(X_scaled)\n",
    "\n",
    "   print('Starting a grid search...')   \n",
    "   saleslib.run_sales_grid_search_loop(X_pca, y, metrics_list, testsize_list, CV_list, random_state_list, param_grid, METRICS_OUTPUT_PATH)\n",
    "   print('Finished a grid search.')\n",
    "\n",
    "print(f'Experiment finished at {saleslib.get_current_timestamp()}')\n",
    "print('=============== FINISHED EXPERIMENT ===============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list      = ['Precision', 'Recall', 'roc_auc', 'F1', 'roc_auc_score', \n",
    "                     'neg_log_loss', 'Brier Score Loss', \n",
    "                     'auc'] \n",
    "\n",
    "# final model\n",
    "TEST_SIZE = 0.2\n",
    "CV= 7\n",
    "RANDOM_SEED = 123456\n",
    "NUM_PCA_COMPONENTS = 5\n",
    "param_grid = {'learning_rate': [0.05], 'max_depth': [16], 'n_estimators': [10000]}\n",
    "plot_grid_search_scores(param_to_study: str, clf, scoring, metric_to_optimize, scale='linear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
