{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling IoT Malware Classification using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pyarrow\n",
    "\n",
    "# built in modules\n",
    "from datetime import datetime\n",
    "#tml.get_current_timestamp()\n",
    "time_start_notebook =  datetime.now()\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# PIP modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skm\n",
    "from   xgboost import XGBClassifier\n",
    "\n",
    "# My custom Python module\n",
    "######################### DON'T TOUCH ANYTHING BELOW #########################\n",
    "newpath = '..'\n",
    "if not newpath in sys.path:\n",
    "    sys.path.insert(1, newpath)\n",
    "del newpath\n",
    "import tim_ml_lib as tml    # works\n",
    "importlib.reload(tml)     # reload it since I'm frequently making changes.\n",
    "######################### DON'T TOUCH ANYTHING ABOVE #########################\n",
    "\n",
    "# some common, basic setup\n",
    "tml.initialize_random_seeds()\n",
    "tml.initialize_display_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_FILEPATH      = # os.path.join('data', 'REPLACEME.csv')\n",
    "INPUT_FILEPATH      = './data/CTU-IoT-Malware-Capture_ready2train.csv.gz'\n",
    "\n",
    "PRIMARY_METRIC      = 'F1'        # key from 'scoring' dict\n",
    "N_JOBS              = tml.get_ideal_num_jobs()  # number of CPU cores to use\n",
    "CV                  = 7                         # cross validation - number of folds\n",
    "# N_PCA_COMPONENTS    = 5                       # number of dimensions to keep after principal component analysis transformation\n",
    "VERBOSITY_LEVEL     = 0                         # verbose level for GridSearchCV: 0-4\n",
    "ZERO_DIVISION_VALUE = 0                         # \n",
    "LABEL_COLUMN_NAME   = 'is_IoT_malware'\n",
    "RANDOM_STATE        = tml.settings.RANDOM_STATE\n",
    "\n",
    "param_grid = {\n",
    "   'max_depth':     [2],\n",
    "   'n_estimators':  [10, 100], #, 250, 500, 750, 1000],\n",
    "   'learning_rate': [0.9],\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    \"F1\":                 skm.make_scorer(skm.f1_score, zero_division=ZERO_DIVISION_VALUE),  # not a problem source                 \n",
    "    \"Accuracy\":           'accuracy',   # not a problem source\n",
    "    \"Recall\":             skm.make_scorer(skm.recall_score, zero_division=ZERO_DIVISION_VALUE),   # not a problem source\n",
    "    \"Precision\":          skm.make_scorer(skm.precision_score, zero_division=ZERO_DIVISION_VALUE),   # not a problem source           \n",
    "\n",
    "    \"roc_auc\":            \"roc_auc\",   # not a problem source\n",
    "    \"roc_auc_score\":      skm.make_scorer(skm.roc_auc_score),     # not a problem source\n",
    "    #\"auc\":                skm.make_scorer(skm.auc), # PROBLEM!!!!\n",
    "\n",
    "    \"neg_log_loss\":       \"neg_log_loss\",   # not a problem source\n",
    "    \"Brier Score Loss\":   skm.make_scorer(skm.brier_score_loss),   # not a problem source\n",
    "    }\n",
    "\n",
    "# FLOAT_DATATYPE = 'float64[pyarrow]'     # works, when 10% sample, df is 115 MB for float64. No errors\n",
    "FLOAT_DATATYPE = 'float32[pyarrow]'       # works, when 10% sample, df is 75 MB for float32. No errors.  max/min +- 3.4 x 10^38; consumes 131 MB of RAM with float32 and chunksize=6252750 (25%)\n",
    "# FLOAT_DATATYPE = 'float16[pyarrow]'     # ERROR, cannot run\n",
    "\n",
    "TRAINING_DATATYPES = {\n",
    "    'is_IoT_malware':      'uint8[pyarrow]',        # label    \n",
    "    'duration':            FLOAT_DATATYPE,      # float b/c of standardization\n",
    "    'orig_pkts':           FLOAT_DATATYPE,      # float b/c of standardization    \n",
    "    'hour_of_day':         FLOAT_DATATYPE,      # added feature - values ranges from [0,23]\n",
    "    'src_port_range_name': 'uint8[pyarrow]',        # added feature - values ranges from [0,4]\n",
    "    'orig_ip_bytes':       FLOAT_DATATYPE,\n",
    "    'proto_icmp':          'uint8[pyarrow]',\n",
    "    'proto_tcp':           'uint8[pyarrow]',\n",
    "    'proto_udp':           'uint8[pyarrow]'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in Chunks:\n",
    "https://www.vantage-ai.com/en/blog/4-strategies-how-to-deal-with-large-datasets-in-pandas\n",
    "\n",
    "FAILED when using chunksize = 6000000, CV=7\n",
    " * BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
    "\n",
    "\n",
    "using chunksize = 3000000, CV=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Start Chunk # 1, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 1 was successful.\n",
      "Best F1 score: 0.9856652257064976\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 100}\n",
      "========== End loop for chunk # 1 ==========\n",
      "\n",
      "========== Start Chunk # 2, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 2 was successful.\n",
      "Best F1 score: 0.9846174325534693\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 10}\n",
      "========== End loop for chunk # 2 ==========\n",
      "\n",
      "========== Start Chunk # 3, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 3 was successful.\n",
      "Best F1 score: 0.9846761015973949\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 10}\n",
      "========== End loop for chunk # 3 ==========\n",
      "\n",
      "========== Start Chunk # 4, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 4 was successful.\n",
      "Best F1 score: 0.9856481351870585\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 100}\n",
      "========== End loop for chunk # 4 ==========\n",
      "\n",
      "========== Start Chunk # 5, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 5 was successful.\n",
      "Best F1 score: 0.9847412640127576\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 10}\n",
      "========== End loop for chunk # 5 ==========\n",
      "\n",
      "========== Start Chunk # 6, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 6 was successful.\n",
      "Best F1 score: 0.9848135403477104\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 10}\n",
      "========== End loop for chunk # 6 ==========\n",
      "\n",
      "========== Start Chunk # 7, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 7 was successful.\n",
      "Best F1 score: 0.9844672060220828\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 10}\n",
      "========== End loop for chunk # 7 ==========\n",
      "\n",
      "========== Start Chunk # 8, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (3000000, 9)\n",
      "Dataframe size in memory: 63.0 MB\n",
      "X shape: (3000000, 8)\n",
      "y shape: (3000000,)\n",
      "Fitting GridSearch chunk # 8 was successful.\n",
      "Best F1 score: 0.9847041609308037\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 10}\n",
      "========== End loop for chunk # 8 ==========\n",
      "\n",
      "========== Start Chunk # 9, chunksize=3000000 ==========\n",
      "Dataframe chunk shape: (1011003, 9)\n",
      "Dataframe size in memory: 21.2 MB\n",
      "X shape: (1011003, 8)\n",
      "y shape: (1011003,)\n",
      "Fitting GridSearch chunk # 9 was successful.\n",
      "Best F1 score: 0.9855977012648153\n",
      "Parameters associated with best model: {'learning_rate': 0.9, 'max_depth': 2, 'n_estimators': 100}\n",
      "========== End loop for chunk # 9 ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# original file has 25,011,003 rows. I often ran into problems when I went above 25% sample size, but that was with float64\n",
    "# so try 6,252,750\n",
    "chunksize     = 3000000\n",
    "engine        = 'c'          # pyarrow does not support chunking\n",
    "loop_counter  = 1\n",
    "models        = []\n",
    "history_stats = []\n",
    "# loop_max    = 3\n",
    "\n",
    "for df in pd.read_csv(INPUT_FILEPATH, chunksize=chunksize, delimiter=',', engine=engine, dtype=TRAINING_DATATYPES, header=0):\n",
    "    print(f'========== Start Chunk # {loop_counter}, chunksize={chunksize} ==========')\n",
    "    tml.initialize_random_seeds()\n",
    "    \n",
    "    model_generic = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=RANDOM_STATE,\n",
    "        )\n",
    "    \n",
    "    y  = df[LABEL_COLUMN_NAME] # .copy()\n",
    "    X  = df.drop(columns=LABEL_COLUMN_NAME, axis=1)\n",
    "\n",
    "    print(f'Dataframe chunk shape: {df.shape}')\n",
    "    print(f'Dataframe size in memory: {tml.get_total_dataframe_memory_usage(df)}')\n",
    "    print(f'X shape: {X.shape}')\n",
    "    print(f'y shape: {y.shape}')\n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "                        model_generic,\n",
    "                        param_grid,\n",
    "                        verbose=VERBOSITY_LEVEL,\n",
    "                        n_jobs=N_JOBS,\n",
    "                        cv=CV,\n",
    "                        scoring=scoring,\n",
    "                        refit=PRIMARY_METRIC,\n",
    "                        return_train_score=True)\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    print(f'Fitting GridSearch chunk # {loop_counter} was successful.')\n",
    "    stats_dict = tml.write_GridSearchCV_output_to_csv(PRIMARY_METRIC, clf, X, y)\n",
    "\n",
    "    print(f'Best {PRIMARY_METRIC} score: {str(clf.best_score_)}')\n",
    "    print(f'Parameters associated with best model: {str(clf.best_params_)}')\n",
    "\n",
    "    models.append(clf)                \n",
    "    history_stats.append(stats_dict)\n",
    "    print(f'========== End loop for chunk # {loop_counter} ==========\\n')\n",
    "    loop_counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement index based loop to iterate thru both models and history_stats\n",
    "# or put them into the same list as a tuple\n",
    "# for clf in models:\n",
    "#     for plot_x_axis in param_grid.keys():\n",
    "#         fig = tml.plot_grid_search_scores(plot_x_axis, clf, scoring, PRIMARY_METRIC)\n",
    "#         ts = stats_dict['Timestamp']\n",
    "#         guid = stats_dict['Experiment GUID']\n",
    "#         figure_filename = f'experiment_{ts}_{plot_x_axis}_{guid}.png'\n",
    "#         fig.savefig(f'./metrics_history/{figure_filename}')\n",
    "#         print(f'Saved figure as {figure_filename}')\n",
    "#         plt.clf()\n",
    "#         #del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:12:41.534084\n"
     ]
    }
   ],
   "source": [
    "time_end_notebook =  datetime.now()\n",
    "print(time_end_notebook - time_start_notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
